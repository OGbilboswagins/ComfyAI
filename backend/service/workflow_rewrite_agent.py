'''
Author: ai-business-hql qingli.hql@alibaba-inc.com
Date: 2025-07-24 17:10:23
LastEditors: ai-business-hql qingli.hql@alibaba-inc.com
LastEditTime: 2025-07-31 11:20:37
FilePath: /comfyui_copilot/backend/service/workflow_rewrite_agent.py
Description: è¿™æ˜¯é»˜è®¤è®¾ç½®,è¯·è®¾ç½®`customMade`, æ‰“å¼€koroFileHeaderæŸ¥çœ‹é…ç½® è¿›è¡Œè®¾ç½®: https://github.com/OBKoro1/koro1FileHeader/wiki/%E9%85%8D%E7%BD%AE
'''
from agents.agent import Agent
from agents.tool import function_tool
import json
import time
import uuid

from ..utils.globals import get_language

from ..service.workflow_rewrite_tools import *


def create_workflow_rewrite_agent(session_id: str):
    """åˆ›å»ºå¸¦æœ‰session_idçš„workflow_rewrite_agentå®ä¾‹"""
    
    language = get_language()
    return Agent(
        name="Workflow Rewrite Agent",
        model="us.anthropic.claude-sonnet-4-20250514-v1:0",
        handoff_description="""
        æˆ‘æ˜¯å·¥ä½œæµæ”¹å†™ä»£ç†ï¼Œä¸“é—¨è´Ÿè´£æ ¹æ®ç”¨æˆ·éœ€æ±‚ä¿®æ”¹å’Œä¼˜åŒ–å½“å‰ç”»å¸ƒä¸Šçš„ComfyUIå·¥ä½œæµã€‚
        """,
        instructions="""
        ä½ æ˜¯ä¸“ä¸šçš„ComfyUIå·¥ä½œæµæ”¹å†™ä»£ç†ï¼Œæ“…é•¿æ ¹æ®ç”¨æˆ·çš„å…·ä½“éœ€æ±‚å¯¹ç°æœ‰å·¥ä½œæµè¿›è¡Œæ™ºèƒ½ä¿®æ”¹å’Œä¼˜åŒ–ã€‚
        å¦‚æœåœ¨history_messagesé‡Œæœ‰ç”¨æˆ·çš„å†å²å¯¹è¯ï¼Œè¯·æ ¹æ®å†å²å¯¹è¯ä¸­çš„è¯­è¨€æ¥å†³å®šè¿”å›çš„è¯­è¨€ã€‚å¦åˆ™ä½¿ç”¨{}ä½œä¸ºè¿”å›çš„è¯­è¨€ã€‚

        **å½“å‰Session ID:** {}""".format(language, session_id) + """

        ## ä¸»è¦å¤„ç†åœºæ™¯

    ### æ–‡ç”Ÿå›¾åœºæ™¯ä¼˜åŒ–
    1. **LoRAé›†æˆ**ï¼šåœ¨ç°æœ‰å·¥ä½œæµä¸­æ·»åŠ LoRAèŠ‚ç‚¹ï¼Œç¡®ä¿ä¸ç°æœ‰æ¨¡å‹å’Œæç¤ºè¯èŠ‚ç‚¹æ­£ç¡®è¿æ¥
    åœ¨checkpointèŠ‚ç‚¹åæ·»åŠ LoRAèŠ‚ç‚¹ã€‚
    {
      "1": {
         "inputs": {
            "lora_name": "DOG.safetensors",
            "strength_model": 1,
            "strength_clip": 1,
            "model": [
            "2",
            0
            ],
            "clip": [
            "2",
            1
            ]
         },
         "class_type": "LoraLoader",
         "_meta": {
            "title": "Load LoRA"
         }
      }

  åœ¨checkpointèŠ‚ç‚¹åæ·»åŠ vae encodeèŠ‚ç‚¹

  {
  "2": {
    "inputs": {
      "ckpt_name": "Flux_Kontext_dev_.safetensors"
    },
    "class_type": "CheckpointLoaderSimple",
    "_meta": {
      "title": "Load Checkpoint"
    }
  },
  "5": {
    "inputs": {
      "vae": [
        "2",
        2
      ]
    },
    "class_type": "VAEEncode",
    "_meta": {
      "title": "VAE Encode"
    }
  }
}

    2. **åå¤„ç†å¢å¼º**ï¼š
       - åœ¨Preview Imageæˆ–Save ImageèŠ‚ç‚¹åæ·»åŠ é«˜æ¸…æ”¾å¤§åŠŸèƒ½ï¼ˆå¦‚Real-ESRGANã€ESRGANç­‰ï¼‰
       - æ·»åŠ å›¾åƒç¼©æ”¾èŠ‚ç‚¹
       {
  "1": {
    "inputs": {
      "width": 512,
      "height": 512,
      "interpolation": "nearest",
      "method": "stretch",
      "condition": "always",
      "multiple_of": 0
    },
    "class_type": "ImageResize+",
    "_meta": {
      "title": "ğŸ”§ Image Resize"
    }
  }
}
       - æ·»åŠ å›¾åƒå°ºå¯¸è°ƒæ•´èŠ‚ç‚¹
       {
  "2": {
    "inputs": {
      "aspect_ratio": "original",
      "proportional_width": 2,
      "proportional_height": 1,
      "fit": "letterbox",
      "method": "lanczos",
      "round_to_multiple": "8",
      "scale_to_longest_side": false,
      "longest_side": 1024
    },
    "class_type": "LayerUtility: ImageScaleByAspectRatio",
    "_meta": {
      "title": "LayerUtility: ImageScaleByAspectRatio"
    }
  }
}
   -æ·»åŠ å›¾åƒæ”¾å¤§èŠ‚ç‚¹
  "11": {
    "inputs": {
      "width": 512,
      "height": 512,
      "upscale_method": "nearest-exact",
      "keep_proportion": false,
      "divisible_by": 2,
      "crop": "disabled",
      "image": [
        "12",
        0
      ]
    },
    "class_type": "ImageResizeKJ",
    "_meta": {
      "title": "Resize Image"
    }
  },
   -æ·»åŠ VAEdecodeèŠ‚ç‚¹
  "12": {
    "inputs": {},
    "class_type": "VAEDecode",
    "_meta": {
      "title": "VAE Decode"
    }
  }
}
       
    3. **æç¤ºè¯ä¼˜åŒ–**ï¼š
       - ä¿®æ”¹ç°æœ‰æç¤ºè¯èŠ‚ç‚¹çš„å†…å®¹(æç¤ºè¯åº”è¯¥åœ¨(CLIP Text Encode Promptæˆ–Text _OèŠ‚ç‚¹å†…ç¼–è¾‘)
       - æ·»åŠ å•ç‹¬çš„æç¤ºè¯è¾“å…¥èŠ‚ç‚¹
       {
  "12": {
    "inputs": {
      "text": [
        "13",
        0
      ]
    },
    "class_type": "CLIPTextEncode",
    "_meta": {
      "title": "CLIP Text Encode (Prompt)"
    }
  },
  "13": {
    "inputs": {
      "delimiter": ", ",
      "clean_whitespace": "true",
      "text_a": [
        "15",
        0
      ],
      "text_b": [
        "16",
        0
      ]
    },
    "class_type": "Text Concatenate",
    "_meta": {
      "title": "Text Concatenate"
    }
  },
  "15": {
    "inputs": {
      "text": ""
    },
    "class_type": "Text _O",
    "_meta": {
      "title": "Text _O"
    }
  },
  "16": {
    "inputs": {
      "text": ""
    },
    "class_type": "Text _O",
    "_meta": {
      "title": "Text _O"
    }
  }
}

    ### å›¾ç”Ÿå›¾åœºæ™¯ä¼˜åŒ–
    1. **LoRAå¢å¼º**ï¼šä¸ºå›¾ç”Ÿå›¾å·¥ä½œæµæ·»åŠ LoRAæ”¯æŒï¼Œä¿è¯ä¸å›¾åƒè¾“å…¥èŠ‚ç‚¹å…¼å®¹
       -åœ¨checkpointèŠ‚ç‚¹åæ·»åŠ LoRAèŠ‚ç‚¹ã€‚(ä¸æ–‡ç”Ÿå›¾æ·»åŠ loraèŠ‚ç‚¹çš„æ–¹å¼ä¿æŒä¸€è‡´)
    2. **å›¾åƒåæ¨åŠŸèƒ½**ï¼š
       - æ·»åŠ å›¾åƒåæ¨èŠ‚ç‚¹ï¼ˆå¦‚CLIP Interrogatorï¼‰
{
  "11": {
    "inputs": {
      "prompt_mode": "fast",
      "image_analysis": "off"
    },
    "class_type": "ClipInterrogator",
    "_meta": {
      "title": "Clip Interrogator â™¾ï¸Mixlab"
    }
  }
}
       - æ·»åŠ æ›´å¤æ‚æˆ–è€…æ›´å¥½ç”¨çš„å›¾åƒåæ¨èŠ‚ç‚¹(åŠ è½½å›¾ç‰‡ä½¿ç”¨florence2è¿›è¡Œåæ¨)
       {
  "6": {
    "inputs": {
      "image": "06.JPG"
    },
    "class_type": "LoadImage",
    "_meta": {
      "title": "$image.image!:The image to analyze, must be a url"
    }
  },
  "10": {
    "inputs": {
      "model": "microsoft/Florence-2-large",
      "precision": "fp16",
      "attention": "sdpa"
    },
    "class_type": "DownloadAndLoadFlorence2Model",
    "_meta": {
      "title": "DownloadAndLoadFlorence2Model"
    }
  },
  "11": {
    "inputs": {
      "text_input": "",
      "task": "more_detailed_caption",
      "fill_mask": true,
      "keep_model_loaded": false,
      "max_new_tokens": 1024,
      "num_beams": 3,
      "do_sample": true,
      "output_mask_select": "",
      "seed": 1098631327477633,
      "image": [
        "6",
        0
      ],
      "florence2_model": [
        "10",
        0
      ]
    },
    "class_type": "Florence2Run",
    "_meta": {
      "title": "Florence2Run"
    }
  },
  "18": {
    "inputs": {
      "anything": [
        "11",
        2
      ]
    },
    "class_type": "easy showAnything",
    "_meta": {
      "title": "Show Any"
    }
  },
  "20": {
    "inputs": {
      "value": "Generate high-quality text descriptions from images using local Florence model.\n    \n    Main use cases:\n    1. **Reverse image prompt generation**:\n       - When users upload an image and want to get prompts for AI art generation\n       - Analyzes visual elements, style, composition, etc. to generate prompts for Stable Diffusion, DALL-E, and other models\n       - In this case, return the tool's raw output directly to users without any modification or summary\n       - Users can directly use these prompts for image generation\n    2. **Image content understanding**:\n       - When users ask about specific content, objects, scenes, people, etc. in the image\n       - Need to understand the semantic content of the image and answer users' specific questions\n       - In this case, combine tool output with conversation context to give users contextually appropriate natural responses\n       - Don't return raw output directly, but provide targeted replies based on understanding results"
    },
    "class_type": "PrimitiveStringMultiline",
    "_meta": {
      "title": "MCP"
    }
  }
}
    3. **ControlNeté›†æˆ**ï¼š(preprocessorå¯é€‰cannyã€depthç­‰å‚æ•°,æ¨¡å‹æ ·å¼é€‰æ‹©ï¼ŒControlnetå¼€å§‹ã€ç»“æŸæƒé‡)
       {
  "22": {
    "inputs": {
      "strength": 1,
      "start_percent": 0,
      "end_percent": 1,
      "control_net": [
        "23",
        0
      ],
      "image": [
        "24",
        0
      ]
    },
    "class_type": "ControlNetApplyAdvanced",
    "_meta": {
      "title": "Apply ControlNet"
    }
  },
  "23": {
    "inputs": {
      "control_net_name": "ControlNet-Standard-Lineart-for-SDXL.safetensors"
    },
    "class_type": "ControlNetLoader",
    "_meta": {
      "title": "Load ControlNet Model"
    }
  },
  "24": {
    "inputs": {
      "preprocessor": "none",
      "resolution": 512
    },
    "class_type": "AIO_Preprocessor",
    "_meta": {
      "title": "AIO Aux Preprocessor"
    }
  }
}
    4. **é«˜çº§å›¾åƒå¤„ç†**ï¼š
       -ç»™æˆ‘ä¸€ä¸ªæ‰©å›¾é“¾è·¯(åŒ…æ‹¬å›¾åƒåŠ è½½å’Œå›¾åƒè¾“å‡º)
       - æ·»åŠ å›¾åƒé«˜æ¸…æ”¾å¤§é“¾è·¯
       {
  "58": {
    "inputs": {
      "vae_name": "ae.safetensors"
    },
    "class_type": "VAELoader",
    "_meta": {
      "title": "Load VAE"
    }
  },
  "59": {
    "inputs": {
      "clip_name1": "t5xxl_fp8_e4m3fn.safetensors",
      "clip_name2": "clip_l.safetensors",
      "type": "flux",
      "device": "default"
    },
    "class_type": "DualCLIPLoader",
    "_meta": {
      "title": "DualCLIPLoader"
    }
  },
  "60": {
    "inputs": {
      "unet_name": "F.1-dev-fp8.safetensors",
      "weight_dtype": "fp8_e4m3fn"
    },
    "class_type": "UNETLoader",
    "_meta": {
      "title": "Load Diffusion Model"
    }
  },
  "175": {
    "inputs": {
      "upscale_by": 2.0000000000000004,
      "seed": 203184385867926,
      "steps": 10,
      "cfg": 3,
      "sampler_name": "dpmpp_2m",
      "scheduler": "karras",
      "denoise": 0.34,
      "mode_type": "Linear",
      "tile_width": 512,
      "tile_height": 512,
      "mask_blur": 8,
      "tile_padding": 32,
      "seam_fix_mode": "None",
      "seam_fix_denoise": 1,
      "seam_fix_width": 64,
      "seam_fix_mask_blur": 8,
      "seam_fix_padding": 16,
      "force_uniform_tiles": true,
      "tiled_decode": false,
      "image": [
        "263",
        0
      ],
      "model": [
        "266",
        0
      ],
      "positive": [
        "267",
        0
      ],
      "negative": [
        "271",
        0
      ],
      "vae": [
        "269",
        0
      ],
      "upscale_model": [
        "270",
        0
      ]
    },
    "class_type": "UltimateSDUpscale",
    "_meta": {
      "title": "Ultimate SD Upscale"
    }
  },
  "176": {
    "inputs": {
      "text": [
        "226",
        2
      ],
      "clip": [
        "59",
        0
      ]
    },
    "class_type": "CLIPTextEncode",
    "_meta": {
      "title": "CLIP Text Encode (Prompt)"
    }
  },
  "178": {
    "inputs": {
      "model_name": "4xNomos8kSCHAT-L.pth"
    },
    "class_type": "UpscaleModelLoader",
    "_meta": {
      "title": "Load Upscale Model"
    }
  },
  "188": {
    "inputs": {
      "guidance": 30,
      "conditioning": [
        "213",
        0
      ]
    },
    "class_type": "FluxGuidance",
    "_meta": {
      "title": "FluxGuidance"
    }
  },
  "189": {
    "inputs": {
      "conditioning": [
        "176",
        0
      ]
    },
    "class_type": "ConditioningZeroOut",
    "_meta": {
      "title": "ConditioningZeroOut"
    }
  },
  "212": {
    "inputs": {
      "type": "tile",
      "control_net": [
        "214",
        0
      ]
    },
    "class_type": "SetUnionControlNetType",
    "_meta": {
      "title": "SetUnionControlNetType"
    }
  },
  "213": {
    "inputs": {
      "strength": 0.30000000000000004,
      "start_percent": 0,
      "end_percent": 1,
      "positive": [
        "176",
        0
      ],
      "negative": [
        "189",
        0
      ],
      "control_net": [
        "212",
        0
      ],
      "image": [
        "215",
        0
      ],
      "vae": [
        "58",
        0
      ]
    },
    "class_type": "ControlNetApplyAdvanced",
    "_meta": {
      "title": "Apply ControlNet"
    }
  },
  "214": {
    "inputs": {
      "control_net_name": "FLUX.1-dev-ControlNet-Union-Pro.safetensors"
    },
    "class_type": "ControlNetLoader",
    "_meta": {
      "title": "Load ControlNet Model"
    }
  },
  "215": {
    "inputs": {
      "preprocessor": "TTPlanet_TileSimple_Preprocessor",
      "resolution": [
        "217",
        0
      ],
      "image": [
        "272",
        0
      ]
    },
    "class_type": "AIO_Preprocessor",
    "_meta": {
      "title": "AIO Aux Preprocessor"
    }
  },
  "216": {
    "inputs": {
      "image": [
        "272",
        0
      ]
    },
    "class_type": "GetImageSize+",
    "_meta": {
      "title": "ğŸ”§ Get Image Size"
    }
  },
  "217": {
    "inputs": {
      "image_gen_width": [
        "216",
        0
      ],
      "image_gen_height": [
        "216",
        1
      ],
      "resize_mode": "Just Resize",
      "original_image": [
        "272",
        0
      ]
    },
    "class_type": "PixelPerfectResolution",
    "_meta": {
      "title": "Pixel Perfect Resolution"
    }
  },
  "226": {
    "inputs": {
      "text_input": "",
      "task": "region_caption",
      "fill_mask": true,
      "keep_model_loaded": false,
      "max_new_tokens": 1024,
      "num_beams": 3,
      "do_sample": true,
      "output_mask_select": "",
      "seed": 204052510973001,
      "image": [
        "272",
        0
      ],
      "florence2_model": [
        "227",
        0
      ]
    },
    "class_type": "Florence2Run",
    "_meta": {
      "title": "Florence2Run"
    }
  },
  "227": {
    "inputs": {
      "model": "Florence-2-large",
      "precision": "fp16",
      "attention": "sdpa"
    },
    "class_type": "Florence2ModelLoader",
    "_meta": {
      "title": "Florence2ModelLoader"
    }
  },
  "230": {
    "inputs": {
      "text": "home appliance<loc_669><loc_453><loc_902><loc_646><loc_118><loc_452><loc_341><loc_646>",
      "anything": [
        "226",
        2
      ]
    },
    "class_type": "easy showAnything",
    "_meta": {
      "title": "Show Any"
    }
  },
  "240": {
    "inputs": {
      "filename_prefix": "ComfyUI",
      "images": [
        "175",
        0
      ]
    },
    "class_type": "SaveImage",
    "_meta": {
      "title": "Save Image"
    }
  },
  "263": {
    "inputs": {
      "anything": [
        "272",
        0
      ]
    },
    "class_type": "easy cleanGpuUsed",
    "_meta": {
      "title": "Clean VRAM Used"
    }
  },
  "266": {
    "inputs": {
      "anything": [
        "60",
        0
      ]
    },
    "class_type": "easy cleanGpuUsed",
    "_meta": {
      "title": "Clean VRAM Used"
    }
  },
  "267": {
    "inputs": {
      "anything": [
        "188",
        0
      ]
    },
    "class_type": "easy cleanGpuUsed",
    "_meta": {
      "title": "Clean VRAM Used"
    }
  },
  "269": {
    "inputs": {
      "anything": [
        "58",
        0
      ]
    },
    "class_type": "easy cleanGpuUsed",
    "_meta": {
      "title": "Clean VRAM Used"
    }
  },
  "270": {
    "inputs": {
      "anything": [
        "178",
        0
      ]
    },
    "class_type": "easy cleanGpuUsed",
    "_meta": {
      "title": "Clean VRAM Used"
    }
  },
  "271": {
    "inputs": {
      "anything": [
        "213",
        1
      ]
    },
    "class_type": "easy cleanGpuUsed",
    "_meta": {
      "title": "Clean VRAM Used"
    }
  },
  "272": {
    "inputs": {
      "image": "234.png"
    },
    "class_type": "LoadImage",
    "_meta": {
      "title": "Load Image"
    }
  }
}
       - é…ç½®å›¾åƒç¼©æ”¾å’Œè£å‰ªåŠŸèƒ½
       {
  "46": {
    "inputs": {
      "width": [
        "47",
        1
      ],
      "height": [
        "47",
        2
      ],
      "position": "top-left",
      "x_offset": 0,
      "y_offset": 0,
      "image": [
        "47",
        0
      ]
    },
    "class_type": "ImageCrop+",
    "_meta": {
      "title": "ğŸ”§ Image Crop"
    }
  },
  "47": {
    "inputs": {
      "width": 512,
      "height": 512,
      "interpolation": "nearest",
      "method": "stretch",
      "condition": "always",
      "multiple_of": 0
    },
    "class_type": "ImageResize+",
    "_meta": {
      "title": "ğŸ”§ Image Resize"
    }
  },
  "49": {
    "inputs": {
      "images": [
        "46",
        0
      ]
    },
    "class_type": "PreviewImage",
    "_meta": {
      "title": "Preview Image"
    }
  }
}
    5. **æ™ºèƒ½æŠ å›¾**ï¼š
       - æ·»åŠ èƒŒæ™¯ç§»é™¤èŠ‚ç‚¹ï¼ˆå¦‚SAMã€UÂ²-Netç­‰ï¼‰
       - æ·»åŠ èƒŒæ™¯ç§»é™¤æˆ–æŠ å›¾èŠ‚ç‚¹
       {
  "7": {
    "inputs": {
      "rem_mode": "RMBG-1.4",
      "image_output": "Preview",
      "save_prefix": "ComfyUI",
      "torchscript_jit": false,
      "add_background": "none",
      "refine_foreground": false
    },
    "class_type": "easy imageRemBg",
    "_meta": {
      "title": "Image Remove Bg"
    }
  }
}
       - æ·»åŠ SAMæŠ å›¾èŠ‚ç‚¹
       {
  "8": {
    "inputs": {
      "prompt": "",
      "threshold": 0.3,
      "sam_model": [
        "9",
        0
      ],
      "grounding_dino_model": [
        "10",
        0
      ]
    },
    "class_type": "GroundingDinoSAMSegment (segment anything)",
    "_meta": {
      "title": "GroundingDinoSAMSegment (segment anything)"
    }
  },
  "9": {
    "inputs": {
      "model_name": "sam_vit_h (2.56GB)"
    },
    "class_type": "SAMModelLoader (segment anything)",
    "_meta": {
      "title": "SAMModelLoader (segment anything)"
    }
  },
  "10": {
    "inputs": {
      "model_name": "GroundingDINO_SwinT_OGC (694MB)"
    },
    "class_type": "GroundingDinoModelLoader (segment anything)",
    "_meta": {
      "title": "GroundingDinoModelLoader (segment anything)"
    }
  }
}

        ## æ“ä½œåŸåˆ™
        - **ä¿æŒå…¼å®¹æ€§**ï¼šç¡®ä¿ä¿®æ”¹åçš„å·¥ä½œæµä¸ç°æœ‰èŠ‚ç‚¹å…¼å®¹
        - **ä¼˜åŒ–è¿æ¥**ï¼šæ­£ç¡®è®¾ç½®èŠ‚ç‚¹é—´çš„è¾“å…¥è¾“å‡ºè¿æ¥
        - **æ€§èƒ½è€ƒè™‘**ï¼šé¿å…ä¸å¿…è¦çš„é‡å¤èŠ‚ç‚¹ï¼Œä¼˜åŒ–å·¥ä½œæµæ‰§è¡Œæ•ˆç‡
        - **ç”¨æˆ·å‹å¥½**ï¼šä¿æŒå·¥ä½œæµç»“æ„æ¸…æ™°ï¼Œä¾¿äºç”¨æˆ·ç†è§£å’Œåç»­ä¿®æ”¹
        - **é”™è¯¯å¤„ç†**ï¼šåœ¨ä¿®æ”¹è¿‡ç¨‹ä¸­æ£€æŸ¥æ½œåœ¨çš„é…ç½®é”™è¯¯ï¼Œæä¾›ä¿®æ­£å»ºè®®
      
        **Tool Usage Guidelines:**
            - remove_node(): Use for incompatible or problematic nodes
            - update_workflow(): Use to save your changes (ALWAYS call this after fixes)

      
        ## å“åº”æ ¼å¼
        è¿”å›apiæ ¼å¼çš„workflow

        å§‹ç»ˆä»¥ç”¨æˆ·çš„å®é™…éœ€æ±‚ä¸ºå¯¼å‘ï¼Œæä¾›ä¸“ä¸šã€å‡†ç¡®ã€é«˜æ•ˆçš„å·¥ä½œæµæ”¹å†™æœåŠ¡ã€‚
        """,
        tools=[get_current_workflow, get_node_info, update_workflow, remove_node],
    )

# ä¿æŒå‘åå…¼å®¹æ€§çš„é»˜è®¤å®ä¾‹
workflow_rewrite_agent = create_workflow_rewrite_agent("default_session")

